{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11830233",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skyfield.api import load, Topos\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "from timezonefinder import TimezoneFinder\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c4217",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "MIN_ISS_ALTITUDE = 10.0  # Minimum ISS elevation threshold (°)\n",
    "SUN_ALTITUDE_THRESHOLD = -6.0  # Nighttime threshold (°)\n",
    "PREDICTION_DAYS = 30  # Prediction length in days\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "TIME_FORMAT = \"%H:%M:%S\"\n",
    "DB_NAME = \"iss_observations.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078c84a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def init_db():\n",
    "    \"\"\"Initialize SQLite database for storing predictions and observations\"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create predictions table\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS predictions\n",
    "                 (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                  latitude REAL,\n",
    "                  longitude REAL,\n",
    "                  prediction_date TEXT,\n",
    "                  rise_time_local TEXT,\n",
    "                  set_time_local TEXT,\n",
    "                  peak_time_local TEXT,\n",
    "                  min_sun_alt REAL,\n",
    "                  iss_peak_alt REAL,\n",
    "                  duration_min REAL,\n",
    "                  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')\n",
    "\n",
    "    # Create observations table - 修正了注释格式，去掉了#\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS observations\n",
    "                 (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                  prediction_id INTEGER,\n",
    "                  observed BOOLEAN,\n",
    "                  actual_rise_time TEXT,\n",
    "                  actual_peak_time TEXT,\n",
    "                  actual_set_time TEXT,\n",
    "                  visibility_rating INTEGER,  -- 1-5 scale\n",
    "                  notes TEXT,\n",
    "                  observed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                  FOREIGN KEY(prediction_id) REFERENCES predictions(id))''')\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb85586",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def save_predictions_to_db(predictions, lat, lon):\n",
    "    \"\"\"Save predictions to database\"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    prediction_ids = []\n",
    "    for pred in predictions:\n",
    "        c.execute('''INSERT INTO predictions \n",
    "                     (latitude, longitude, prediction_date, rise_time_local, \n",
    "                      set_time_local, peak_time_local, min_sun_alt, \n",
    "                      iss_peak_alt, duration_min)\n",
    "                     VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)''',\n",
    "                  (lat, lon, pred[\"Date\"], pred[\"Rise Time (Local)\"],\n",
    "                   pred[\"Set Time (Local)\"], pred[\"Peak Time (Local)\"],\n",
    "                   pred[\"Min Sun Alt(°)\"], pred[\"ISS Peak Alt(°)\"],\n",
    "                   pred[\"Duration (min)\"]))\n",
    "        prediction_ids.append(c.lastrowid)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return prediction_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79afe7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def save_observation_to_db(prediction_id, observed, actual_times, rating, notes):\n",
    "    \"\"\"Save observation data to database\"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute('''INSERT INTO observations \n",
    "                 (prediction_id, observed, actual_rise_time, \n",
    "                  actual_peak_time, actual_set_time, visibility_rating, notes)\n",
    "                 VALUES (?, ?, ?, ?, ?, ?, ?)''',\n",
    "              (prediction_id, 1 if observed else 0,\n",
    "               actual_times.get('rise', ''), actual_times.get('peak', ''),\n",
    "               actual_times.get('set', ''), rating, notes))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd4f1f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_predictions_with_observations():\n",
    "    \"\"\"Get all predictions with their associated observations\"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    query = '''SELECT p.*, o.observed, o.actual_rise_time, o.actual_peak_time,\n",
    "                      o.actual_set_time, o.visibility_rating\n",
    "               FROM predictions p\n",
    "               LEFT JOIN observations o ON p.id = o.prediction_id'''\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343dcf6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_timezone(lat: float, lon: float) -> ZoneInfo:\n",
    "    \"\"\"Return timezone based on latitude/longitude\"\"\"\n",
    "    tf = TimezoneFinder()\n",
    "    tz_name = tf.timezone_at(lat=lat, lng=lon)\n",
    "    return ZoneInfo(tz_name) if tz_name else ZoneInfo(\"UTC\")\n",
    "\n",
    "\n",
    "def utc_to_local(utc_dt: datetime, local_tz: ZoneInfo) -> datetime:\n",
    "    \"\"\"Convert UTC time to local timezone\"\"\"\n",
    "    return utc_dt.astimezone(local_tz)\n",
    "\n",
    "\n",
    "def load_iss_tle() -> tuple:\n",
    "    \"\"\"Load ISS TLE data (with exception handling)\"\"\"\n",
    "    stations_url = 'https://celestrak.org/NORAD/elements/stations.txt'\n",
    "    try:\n",
    "        satellites = load.tle_file(stations_url)\n",
    "        iss = next((sat for sat in satellites if 'ISS' in sat.name), None)\n",
    "        if not iss:\n",
    "            raise ValueError(\"ISS not found in TLE data\")\n",
    "        epoch = iss.epoch.utc_strftime(DATE_FORMAT + \" \" + TIME_FORMAT)\n",
    "        return iss, epoch\n",
    "    except Exception as e:\n",
    "        st.error(f\"Failed to load TLE data: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9d169",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_iss_predictions(lat, lon, start_date):\n",
    "    \"\"\"Generate ISS visibility predictions\"\"\"\n",
    "    # Timezone handling\n",
    "    local_tz = get_timezone(lat, lon)\n",
    "    local_start = datetime.strptime(start_date, DATE_FORMAT).replace(\n",
    "        hour=0, minute=0, second=0, tzinfo=local_tz)\n",
    "    utc_start = local_start.astimezone(ZoneInfo(\"UTC\"))\n",
    "\n",
    "    # Load ISS data\n",
    "    iss, epoch = load_iss_tle()\n",
    "    if not iss:\n",
    "        return None, None\n",
    "\n",
    "    # Initialize objects\n",
    "    ts = load.timescale()\n",
    "    observer = Topos(latitude_degrees=lat, longitude_degrees=lon, elevation_m=50)\n",
    "    eph = load('de421.bsp')\n",
    "    earth = eph['earth']\n",
    "    sun = eph['sun']\n",
    "    observer_earth = earth + observer\n",
    "\n",
    "    # Transit event calculation\n",
    "    passes_data = []\n",
    "\n",
    "    # Time range\n",
    "    t0 = ts.utc(utc_start.year, utc_start.month, utc_start.day)\n",
    "    t1 = t0 + timedelta(days=PREDICTION_DAYS)\n",
    "\n",
    "    # Get events: rise / culmination / set\n",
    "    t_events, event_types = iss.find_events(observer, t0, t1, altitude_degrees=MIN_ISS_ALTITUDE)\n",
    "\n",
    "    # Extract rise/set pairs\n",
    "    rise_set_pairs = []\n",
    "    current_rise = None\n",
    "    for t, event in zip(t_events, event_types):\n",
    "        if event == 0:  # rise\n",
    "            current_rise = t\n",
    "        elif event == 2 and current_rise is not None:  # set\n",
    "            rise_set_pairs.append((current_rise, t))\n",
    "            current_rise = None\n",
    "\n",
    "    # Process each pass\n",
    "    for t_rise, t_set in rise_set_pairs:\n",
    "        dt_rise = t_rise.utc_datetime()\n",
    "        dt_set = t_set.utc_datetime()\n",
    "        dt_peak = dt_rise + (dt_set - dt_rise) / 2\n",
    "        t_peak = ts.from_datetime(dt_peak)\n",
    "\n",
    "        sun_alt_rise, _, _ = observer_earth.at(t_rise).observe(sun).apparent().altaz()\n",
    "        sun_alt_peak, _, _ = observer_earth.at(t_peak).observe(sun).apparent().altaz()\n",
    "        sun_alt_set, _, _ = observer_earth.at(t_set).observe(sun).apparent().altaz()\n",
    "\n",
    "        min_sun_alt = min(sun_alt_rise.degrees, sun_alt_peak.degrees, sun_alt_set.degrees)\n",
    "\n",
    "        iss_sunlit = (iss.at(t_rise).is_sunlit(eph) or\n",
    "                      iss.at(t_peak).is_sunlit(eph) or\n",
    "                      iss.at(t_set).is_sunlit(eph))\n",
    "\n",
    "        iss_position = iss.at(t_peak)\n",
    "        observer_position = observer.at(t_peak)\n",
    "        alt, az, _ = (iss_position - observer_position).altaz()\n",
    "        iss_peak_alt = alt.degrees\n",
    "\n",
    "        if (sun_alt_rise.degrees < SUN_ALTITUDE_THRESHOLD or\n",
    "            sun_alt_peak.degrees < SUN_ALTITUDE_THRESHOLD or\n",
    "            sun_alt_set.degrees < SUN_ALTITUDE_THRESHOLD) and iss_sunlit:\n",
    "            local_rise = utc_to_local(dt_rise, local_tz)\n",
    "            local_set = utc_to_local(dt_set, local_tz)\n",
    "            local_peak = utc_to_local(dt_peak, local_tz)\n",
    "\n",
    "            passes_data.append({\n",
    "                \"Date\": local_rise.strftime(DATE_FORMAT),\n",
    "                \"Rise Time (Local)\": local_rise.strftime(TIME_FORMAT),\n",
    "                \"Set Time (Local)\": local_set.strftime(TIME_FORMAT),\n",
    "                \"Peak Time (Local)\": local_peak.strftime(TIME_FORMAT),\n",
    "                \"Min Sun Alt(°)\": round(min_sun_alt, 1),\n",
    "                \"ISS Peak Alt(°)\": round(iss_peak_alt, 1),\n",
    "                \"Duration (min)\": round((dt_set - dt_rise).total_seconds() / 60, 1)\n",
    "            })\n",
    "\n",
    "    return passes_data, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995371e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy_metrics(df):\n",
    "    \"\"\"Calculate prediction accuracy metrics\"\"\"\n",
    "    # Filter to only predictions that have observations\n",
    "    observed_predictions = df[df['observed'].notna()]\n",
    "\n",
    "    if len(observed_predictions) == 0:\n",
    "        return None\n",
    "\n",
    "    # Calculate overall accuracy (predicted pass was actually observed)\n",
    "    accuracy = observed_predictions['observed'].mean() * 100\n",
    "\n",
    "    # Calculate time differences where we have actual times\n",
    "    time_diff_metrics = {}\n",
    "\n",
    "    # Process rise time differences\n",
    "    rise_times = observed_predictions[observed_predictions['actual_rise_time'] != '']\n",
    "    if len(rise_times) > 0:\n",
    "        rise_diff = []\n",
    "        for _, row in rise_times.iterrows():\n",
    "            pred = datetime.strptime(f\"{row['prediction_date']} {row['rise_time_local']}\",\n",
    "                                     f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            actual = datetime.strptime(f\"{row['prediction_date']} {row['actual_rise_time']}\",\n",
    "                                       f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            rise_diff.append(abs((actual - pred).total_seconds() / 60))  # minutes\n",
    "        time_diff_metrics['rise'] = {\n",
    "            'mean': np.mean(rise_diff),\n",
    "            'median': np.median(rise_diff),\n",
    "            'max': np.max(rise_diff)\n",
    "        }\n",
    "\n",
    "    # Process peak time differences\n",
    "    peak_times = observed_predictions[observed_predictions['actual_peak_time'] != '']\n",
    "    if len(peak_times) > 0:\n",
    "        peak_diff = []\n",
    "        for _, row in peak_times.iterrows():\n",
    "            pred = datetime.strptime(f\"{row['prediction_date']} {row['peak_time_local']}\",\n",
    "                                     f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            actual = datetime.strptime(f\"{row['prediction_date']} {row['actual_peak_time']}\",\n",
    "                                       f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            peak_diff.append(abs((actual - pred).total_seconds() / 60))  # minutes\n",
    "        time_diff_metrics['peak'] = {\n",
    "            'mean': np.mean(peak_diff),\n",
    "            'median': np.median(peak_diff),\n",
    "            'max': np.max(peak_diff)\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'total_predictions': len(df),\n",
    "        'total_observed': len(observed_predictions),\n",
    "        'accuracy': accuracy,\n",
    "        'time_diffs': time_diff_metrics\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff755d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_visualizations(df):\n",
    "    \"\"\"Create visualization of prediction accuracy\"\"\"\n",
    "    # Filter to only predictions that have observations\n",
    "    observed_predictions = df[df['observed'].notna()]\n",
    "\n",
    "    if len(observed_predictions) == 0:\n",
    "        st.info(\"No observation data available for visualization. Enter some observation data first.\")\n",
    "        return\n",
    "\n",
    "    # 1. Observation Rate Bar Chart\n",
    "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    observation_counts = observed_predictions['observed'].value_counts()\n",
    "    ax1.bar(['Observed', 'Not Observed'],\n",
    "            [observation_counts.get(1, 0), observation_counts.get(0, 0)],\n",
    "            color=['green', 'red'])\n",
    "    ax1.set_title('Observation Rate of Predicted Passes')\n",
    "    ax1.set_ylabel('Number of Passes')\n",
    "    ax1.set_ylim(0, max(observation_counts) + 1)\n",
    "    st.pyplot(fig1)\n",
    "\n",
    "    # 2. Time Difference Histogram\n",
    "    time_diffs = []\n",
    "    labels = []\n",
    "\n",
    "    # Check for rise time differences\n",
    "    rise_times = observed_predictions[observed_predictions['actual_rise_time'] != '']\n",
    "    if len(rise_times) > 0:\n",
    "        for _, row in rise_times.iterrows():\n",
    "            pred = datetime.strptime(f\"{row['prediction_date']} {row['rise_time_local']}\",\n",
    "                                     f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            actual = datetime.strptime(f\"{row['prediction_date']} {row['actual_rise_time']}\",\n",
    "                                       f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            time_diffs.append(abs((actual - pred).total_seconds() / 60))  # minutes\n",
    "            labels.append('Rise')\n",
    "\n",
    "    # Check for peak time differences\n",
    "    peak_times = observed_predictions[observed_predictions['actual_peak_time'] != '']\n",
    "    if len(peak_times) > 0:\n",
    "        for _, row in peak_times.iterrows():\n",
    "            pred = datetime.strptime(f\"{row['prediction_date']} {row['peak_time_local']}\",\n",
    "                                     f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            actual = datetime.strptime(f\"{row['prediction_date']} {row['actual_peak_time']}\",\n",
    "                                       f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            time_diffs.append(abs((actual - pred).total_seconds() / 60))  # minutes\n",
    "            labels.append('Peak')\n",
    "\n",
    "    if time_diffs:\n",
    "        fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "        ax2.hist(time_diffs, bins=10, alpha=0.7)\n",
    "        ax2.set_title('Distribution of Time Prediction Errors (minutes)')\n",
    "        ax2.set_xlabel('Time Difference (minutes)')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        st.pyplot(fig2)\n",
    "\n",
    "    # 3. Visibility vs Predicted Altitude\n",
    "    rated_obs = observed_predictions[observed_predictions['visibility_rating'].notna()]\n",
    "    if len(rated_obs) > 0:\n",
    "        fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "        ax3.scatter(rated_obs['iss_peak_alt'], rated_obs['visibility_rating'])\n",
    "        ax3.set_title('Visibility Rating vs Predicted ISS Peak Altitude')\n",
    "        ax3.set_xlabel('Predicted ISS Peak Altitude (°)')\n",
    "        ax3.set_ylabel('Visibility Rating (1-5)')\n",
    "        ax3.set_ylim(0, 6)\n",
    "        st.pyplot(fig3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9fc5e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.set_page_config(page_title=\"ISS Visibility Predictor\", layout=\"wide\")\n",
    "    st.title(\"ISS Visibility Predictor & Tracker\")\n",
    "\n",
    "    # Initialize database\n",
    "    init_db()\n",
    "\n",
    "    # Create tabs\n",
    "    tab1, tab2, tab3 = st.tabs([\"Generate Predictions\", \"Log Observations\", \"Analysis & Visualization\"])\n",
    "\n",
    "    with tab1:\n",
    "        st.header(\"Generate ISS Visibility Predictions\")\n",
    "\n",
    "        # User input\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            lat = st.number_input(\"Latitude (°)\", min_value=-90.0, max_value=90.0, value=0.0, step=0.01)\n",
    "            lon = st.number_input(\"Longitude (°)\", min_value=-180.0, max_value=180.0, value=0.0, step=0.01)\n",
    "\n",
    "        with col2:\n",
    "            today = datetime.now().strftime(DATE_FORMAT)\n",
    "            start_date = st.text_input(\"Start Date (YYYY-MM-DD)\", value=today)\n",
    "\n",
    "        if st.button(\"Generate Predictions\"):\n",
    "            # Validate inputs\n",
    "            try:\n",
    "                datetime.strptime(start_date, DATE_FORMAT)\n",
    "            except ValueError:\n",
    "                st.error(\"Invalid date format. Please use YYYY-MM-DD.\")\n",
    "                return\n",
    "\n",
    "            if not (-90 <= lat <= 90 and -180 <= lon <= 180):\n",
    "                st.error(\"Latitude must be between -90 and 90, longitude between -180 and 180.\")\n",
    "                return\n",
    "\n",
    "            # Generate predictions\n",
    "            with st.spinner(\"Calculating ISS visibility predictions...\"):\n",
    "                predictions, epoch = generate_iss_predictions(lat, lon, start_date)\n",
    "\n",
    "                if predictions:\n",
    "                    st.success(f\"Successfully generated {len(predictions)} predictions! TLE Epoch: {epoch}\")\n",
    "\n",
    "                    # Save to database\n",
    "                    prediction_ids = save_predictions_to_db(predictions, lat, lon)\n",
    "\n",
    "                    # Display predictions\n",
    "                    df = pd.DataFrame(predictions)\n",
    "                    st.dataframe(df)\n",
    "\n",
    "                    # Add download option\n",
    "                    csv = df.to_csv(index=False)\n",
    "                    st.download_button(\n",
    "                        label=\"Download predictions as CSV\",\n",
    "                        data=csv,\n",
    "                        file_name=\"iss_predictions.csv\",\n",
    "                        mime=\"text/csv\",\n",
    "                    )\n",
    "                else:\n",
    "                    st.warning(\"No visible nighttime ISS passes found for the given parameters.\")\n",
    "\n",
    "    with tab2:\n",
    "        st.header(\"Log Observation Data\")\n",
    "\n",
    "        # Get all predictions without observations\n",
    "        conn = sqlite3.connect(DB_NAME)\n",
    "        query = '''SELECT p.id, p.prediction_date, p.rise_time_local, p.peak_time_local, \n",
    "                          p.set_time_local, p.iss_peak_alt, p.latitude, p.longitude\n",
    "                   FROM predictions p\n",
    "                   LEFT JOIN observations o ON p.id = o.prediction_id\n",
    "                   WHERE o.id IS NULL'''\n",
    "        predictions_df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "\n",
    "        if len(predictions_df) == 0:\n",
    "            st.info(\"No predictions available to log observations for. Generate some predictions first.\")\n",
    "        else:\n",
    "            # Let user select a prediction to log\n",
    "            prediction_id = st.selectbox(\n",
    "                \"Select a prediction to log an observation for:\",\n",
    "                predictions_df['id'],\n",
    "                format_func=lambda\n",
    "                    x: f\"ID {x}: {predictions_df.loc[predictions_df['id'] == x, 'prediction_date'].iloc[0]} \"\n",
    "                       f\"({predictions_df.loc[predictions_df['id'] == x, 'rise_time_local'].iloc[0]} - \"\n",
    "                       f\"{predictions_df.loc[predictions_df['id'] == x, 'set_time_local'].iloc[0]})\"\n",
    "            )\n",
    "\n",
    "            # Get selected prediction details\n",
    "            selected_pred = predictions_df[predictions_df['id'] == prediction_id].iloc[0]\n",
    "\n",
    "            # Display prediction details\n",
    "            st.subheader(\"Prediction Details\")\n",
    "            st.write(f\"Date: {selected_pred['prediction_date']}\")\n",
    "            st.write(f\"Location: Lat {selected_pred['latitude']}, Lon {selected_pred['longitude']}\")\n",
    "            st.write(f\"Predicted Rise Time: {selected_pred['rise_time_local']}\")\n",
    "            st.write(f\"Predicted Peak Time: {selected_pred['peak_time_local']}\")\n",
    "            st.write(f\"Predicted Set Time: {selected_pred['set_time_local']}\")\n",
    "            st.write(f\"Predicted Peak Altitude: {selected_pred['iss_peak_alt']}°\")\n",
    "\n",
    "            # Observation form\n",
    "            st.subheader(\"Observation Data\")\n",
    "            observed = st.radio(\"Did you observe the ISS during this pass?\", [\"Yes\", \"No\"])\n",
    "            observed_bool = observed == \"Yes\"\n",
    "\n",
    "            actual_times = {}\n",
    "            if observed_bool:\n",
    "                col1, col2, col3 = st.columns(3)\n",
    "                with col1:\n",
    "                    actual_rise = st.text_input(\"Actual Rise Time (HH:MM:SS)\", value=selected_pred['rise_time_local'])\n",
    "                    actual_times['rise'] = actual_rise\n",
    "                with col2:\n",
    "                    actual_peak = st.text_input(\"Actual Peak Time (HH:MM:SS)\", value=selected_pred['peak_time_local'])\n",
    "                    actual_times['peak'] = actual_peak\n",
    "                with col3:\n",
    "                    actual_set = st.text_input(\"Actual Set Time (HH:MM:SS)\", value=selected_pred['set_time_local'])\n",
    "                    actual_times['set'] = actual_set\n",
    "\n",
    "                visibility = st.slider(\"Visibility Rating (1=Poor, 5=Excellent)\", 1, 5, 3)\n",
    "            else:\n",
    "                visibility = None\n",
    "\n",
    "            notes = st.text_area(\"Additional Notes (e.g., weather conditions, obstacles)\", \"\")\n",
    "\n",
    "            if st.button(\"Save Observation\"):\n",
    "                # Validate time formats if provided\n",
    "                time_format_valid = True\n",
    "                if observed_bool:\n",
    "                    for time_type, time_str in actual_times.items():\n",
    "                        try:\n",
    "                            datetime.strptime(time_str, TIME_FORMAT)\n",
    "                        except ValueError:\n",
    "                            st.error(f\"Invalid {time_type} time format. Please use HH:MM:SS.\")\n",
    "                            time_format_valid = False\n",
    "                            break\n",
    "\n",
    "                if time_format_valid:\n",
    "                    save_observation_to_db(prediction_id, observed_bool, actual_times, visibility, notes)\n",
    "                    st.success(\"Observation saved successfully!\")\n",
    "                    st.rerun()\n",
    "\n",
    "    with tab3:\n",
    "        st.header(\"Prediction Accuracy Analysis\")\n",
    "\n",
    "        # Get all data\n",
    "        df = get_all_predictions_with_observations()\n",
    "\n",
    "        if len(df) == 0:\n",
    "            st.info(\"No prediction data available. Generate some predictions first.\")\n",
    "        else:\n",
    "            # Calculate metrics\n",
    "            metrics = calculate_accuracy_metrics(df)\n",
    "\n",
    "            if metrics:\n",
    "                # Display metrics\n",
    "                col1, col2, col3 = st.columns(3)\n",
    "                with col1:\n",
    "                    st.metric(\"Total Predictions\", metrics['total_predictions'])\n",
    "                with col2:\n",
    "                    st.metric(\"Predictions with Observations\", metrics['total_observed'])\n",
    "                with col3:\n",
    "                    st.metric(\"Observation Accuracy\", f\"{metrics['accuracy']:.1f}%\")\n",
    "\n",
    "                # Display time difference metrics\n",
    "                if metrics['time_diffs']:\n",
    "                    st.subheader(\"Time Prediction Accuracy (minutes)\")\n",
    "                    time_metrics_df = pd.DataFrame()\n",
    "\n",
    "                    for time_type, stats in metrics['time_diffs'].items():\n",
    "                        time_metrics_df = pd.concat([time_metrics_df, pd.DataFrame({\n",
    "                            'Time Type': [time_type.capitalize()],\n",
    "                            'Mean Difference': [f\"{stats['mean']:.1f}\"],\n",
    "                            'Median Difference': [f\"{stats['median']:.1f}\"],\n",
    "                            'Max Difference': [f\"{stats['max']:.1f}\"]\n",
    "                        })], ignore_index=True)\n",
    "\n",
    "                    st.dataframe(time_metrics_df)\n",
    "\n",
    "            # Display visualizations\n",
    "            st.subheader(\"Accuracy Visualizations\")\n",
    "            create_visualizations(df)\n",
    "\n",
    "            # Display raw data\n",
    "            with st.expander(\"View Raw Data\"):\n",
    "                st.dataframe(df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb63a2",
   "metadata": {},
   "source": [
    "# ISS Visibility Predictor - Notebook\n",
    "\n",
    "This notebook breaks the `First3.py` application into modular cells. Each module is introduced with a short English explanation, followed by the corresponding Python code cell. The code is kept identical to the original file where possible so you can run or copy cells back into scripts as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b93d2e",
   "metadata": {},
   "source": [
    "## 1) Imports\n",
    "\n",
    "This cell contains all third-party and stdlib imports used across the application. These imports set up dependencies for Streamlit, Skyfield, timezone handling, pandas/numpy for data, plotting, and SQLite for persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skyfield.api import load, Topos\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "from timezonefinder import TimezoneFinder\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae79c79",
   "metadata": {},
   "source": [
    "## 2) Constants\n",
    "\n",
    "This cell defines configuration constants used across the app, such as minimum visibility altitude, night threshold, date/time formats, prediction window, and the SQLite database filename. Adjust these constants to change app behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b835cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== CONSTANTS =====================\n",
    "MIN_ISS_ALTITUDE = 10.0  # Minimum ISS elevation threshold (°)\n",
    "SUN_ALTITUDE_THRESHOLD = -6.0  # Nighttime threshold (°)\n",
    "PREDICTION_DAYS = 30  # Prediction length in days\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "TIME_FORMAT = \"%H:%M:%S\"\n",
    "DB_NAME = \"iss_observations.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452af3bc",
   "metadata": {},
   "source": [
    "## 3) Database functions\n",
    "\n",
    "These functions initialize an SQLite database and provide helpers to save predictions and observations. They separate persistence concerns from prediction logic. Inputs/outputs: Python dicts/lists and SQLite rows. Error modes: basic exceptions from sqlite3 will surface to the caller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== DATABASE FUNCTIONS =====================\n",
    "def init_db():\n",
    "    \"\"\"Initialize SQLite database for storing predictions and observations\"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create predictions table\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS predictions\n",
    "                 (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                  latitude REAL,\n",
    "                  longitude REAL,\n",
    "                  prediction_date TEXT,\n",
    "                  rise_time_local TEXT,\n",
    "                  set_time_local TEXT,\n",
    "                  peak_time_local TEXT,\n",
    "                  min_sun_alt REAL,\n",
    "                  iss_peak_alt REAL,\n",
    "                  duration_min REAL,\n",
    "                  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')\n",
    "\n",
    "    # Create observations table - #\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS observations\n",
    "                 (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                  prediction_id INTEGER,\n",
    "                  observed BOOLEAN,\n",
    "                  actual_rise_time TEXT,\n",
    "                  actual_peak_time TEXT,\n",
    "                  actual_set_time TEXT,\n",
    "                  visibility_rating INTEGER,  -- 1-5 scale\n",
    "                  notes TEXT,\n",
    "                  observed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                  FOREIGN KEY(prediction_id) REFERENCES predictions(id))''')\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def save_predictions_to_db(predictions, lat, lon):\n",
    "    \"\"\"Save predictions to database\"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    prediction_ids = []\n",
    "    for pred in predictions:\n",
    "        c.execute('''INSERT INTO predictions \n",
    "                     (latitude, longitude, prediction_date, rise_time_local, \n",
    "                      set_time_local, peak_time_local, min_sun_alt, \n",
    "                      iss_peak_alt, duration_min)\n",
    "                     VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)''',\n",
    "                  (lat, lon, pred[\"Date\"], pred[\"Rise Time (Local)\"],\n",
    "                   pred[\"Set Time (Local)\"], pred[\"Peak Time (Local)\"],\n",
    "                   pred[\"Min Sun Alt(°)\"], pred[\"ISS Peak Alt(°)\"],\n",
    "                   pred[\"Duration (min)\"]))\n",
    "        prediction_ids.append(c.lastrowid)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return prediction_ids\n",
    "\n",
    "\n",
    "def save_observation_to_db(prediction_id, observed, actual_times, rating, notes):\n",
    "    \"\"\"Save observation data to database\"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute('''INSERT INTO observations \n",
    "                 (prediction_id, observed, actual_rise_time, \n",
    "                  actual_peak_time, actual_set_time, visibility_rating, notes)\n",
    "                 VALUES (?, ?, ?, ?, ?, ?, ?)''',\n",
    "              (prediction_id, 1 if observed else 0,\n",
    "               actual_times.get('rise', ''), actual_times.get('peak', ''),\n",
    "               actual_times.get('set', ''), rating, notes))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def get_all_predictions_with_observations():\n",
    "    \"\"\"Get all predictions with their associated observations\"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    query = '''SELECT p.*, o.observed, o.actual_rise_time, o.actual_peak_time,\n",
    "                      o.actual_set_time, o.visibility_rating\n",
    "               FROM predictions p\n",
    "               LEFT JOIN observations o ON p.id = o.prediction_id'''\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b834b572",
   "metadata": {},
   "source": [
    "## 4) Utility functions\n",
    "\n",
    "Helper functions for timezone resolution and time conversion, plus a small wrapper to load ISS TLE data with basic error handling. Inputs: lat/lon or datetime objects. Outputs: ZoneInfo, converted datetimes, or (iss, epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea5c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== UTILITY FUNCTIONS =====================\n",
    "def get_timezone(lat: float, lon: float) -> ZoneInfo:\n",
    "    \"\"\"Return timezone based on latitude/longitude\"\"\"\n",
    "    tf = TimezoneFinder()\n",
    "    tz_name = tf.timezone_at(lat=lat, lng=lon)\n",
    "    return ZoneInfo(tz_name) if tz_name else ZoneInfo(\"UTC\")\n",
    "\n",
    "\n",
    "def utc_to_local(utc_dt: datetime, local_tz: ZoneInfo) -> datetime:\n",
    "    \"\"\"Convert UTC time to local timezone\"\"\"\n",
    "    return utc_dt.astimezone(local_tz)\n",
    "\n",
    "\n",
    "def load_iss_tle() -> tuple:\n",
    "    \"\"\"Load ISS TLE data (with exception handling)\"\"\"\n",
    "    stations_url = 'https://celestrak.org/NORAD/elements/stations.txt'\n",
    "    try:\n",
    "        satellites = load.tle_file(stations_url)\n",
    "        iss = next((sat for sat in satellites if 'ISS' in sat.name), None)\n",
    "        if not iss:\n",
    "            raise ValueError(\"ISS not found in TLE data\")\n",
    "        epoch = iss.epoch.utc_strftime(DATE_FORMAT + \" \" + TIME_FORMAT)\n",
    "        return iss, epoch\n",
    "    except Exception as e:\n",
    "        st.error(f\"Failed to load TLE data: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97b60c",
   "metadata": {},
   "source": [
    "## 5) Prediction functions\n",
    "\n",
    "This cell contains the core logic that uses Skyfield to compute ISS rise/peak/set events for an observer and filters passes that are visible at night (based on sun altitude) while the ISS is sunlit. Output: list of pass dictionaries and the TLE epoch string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f65b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== PREDICTION FUNCTIONS =====================\n",
    "def generate_iss_predictions(lat, lon, start_date):\n",
    "    \"\"\"Generate ISS visibility predictions\"\"\"\n",
    "    # Timezone handling\n",
    "    local_tz = get_timezone(lat, lon)\n",
    "    local_start = datetime.strptime(start_date, DATE_FORMAT).replace(\n",
    "        hour=0, minute=0, second=0, tzinfo=local_tz)\n",
    "    utc_start = local_start.astimezone(ZoneInfo(\"UTC\"))\n",
    "\n",
    "    # Load ISS data\n",
    "    iss, epoch = load_iss_tle()\n",
    "    if not iss:\n",
    "        return None, None\n",
    "\n",
    "    # Initialize objects\n",
    "    ts = load.timescale()\n",
    "    observer = Topos(latitude_degrees=lat, longitude_degrees=lon, elevation_m=50)\n",
    "    eph = load('de421.bsp')\n",
    "    earth = eph['earth']\n",
    "    sun = eph['sun']\n",
    "    observer_earth = earth + observer\n",
    "\n",
    "    # Transit event calculation\n",
    "    passes_data = []\n",
    "\n",
    "    # Time range\n",
    "    t0 = ts.utc(utc_start.year, utc_start.month, utc_start.day)\n",
    "    t1 = t0 + timedelta(days=PREDICTION_DAYS)\n",
    "\n",
    "    # Get events: rise / culmination / set\n",
    "    t_events, event_types = iss.find_events(observer, t0, t1, altitude_degrees=MIN_ISS_ALTITUDE)\n",
    "\n",
    "    # Extract rise/set pairs\n",
    "    rise_set_pairs = []\n",
    "    current_rise = None\n",
    "    for t, event in zip(t_events, event_types):\n",
    "        if event == 0:  # rise\n",
    "            current_rise = t\n",
    "        elif event == 2 and current_rise is not None:  # set\n",
    "            rise_set_pairs.append((current_rise, t))\n",
    "            current_rise = None\n",
    "\n",
    "    # Process each pass\n",
    "    for t_rise, t_set in rise_set_pairs:\n",
    "        dt_rise = t_rise.utc_datetime()\n",
    "        dt_set = t_set.utc_datetime()\n",
    "        dt_peak = dt_rise + (dt_set - dt_rise) / 2\n",
    "        t_peak = ts.from_datetime(dt_peak)\n",
    "\n",
    "        sun_alt_rise, _, _ = observer_earth.at(t_rise).observe(sun).apparent().altaz()\n",
    "        sun_alt_peak, _, _ = observer_earth.at(t_peak).observe(sun).apparent().altaz()\n",
    "        sun_alt_set, _, _ = observer_earth.at(t_set).observe(sun).apparent().altaz()\n",
    "\n",
    "        min_sun_alt = min(sun_alt_rise.degrees, sun_alt_peak.degrees, sun_alt_set.degrees)\n",
    "\n",
    "        iss_sunlit = (iss.at(t_rise).is_sunlit(eph) or\n",
    "                      iss.at(t_peak).is_sunlit(eph) or\n",
    "                      iss.at(t_set).is_sunlit(eph))\n",
    "\n",
    "        iss_position = iss.at(t_peak)\n",
    "        observer_position = observer.at(t_peak)\n",
    "        alt, az, _ = (iss_position - observer_position).altaz()\n",
    "        iss_peak_alt = alt.degrees\n",
    "\n",
    "        if (sun_alt_rise.degrees < SUN_ALTITUDE_THRESHOLD or\n",
    "            sun_alt_peak.degrees < SUN_ALTITUDE_THRESHOLD or\n",
    "            sun_alt_set.degrees < SUN_ALTITUDE_THRESHOLD) and iss_sunlit:\n",
    "            local_rise = utc_to_local(dt_rise, local_tz)\n",
    "            local_set = utc_to_local(dt_set, local_tz)\n",
    "            local_peak = utc_to_local(dt_peak, local_tz)\n",
    "\n",
    "            passes_data.append({\n",
    "                \"Date\": local_rise.strftime(DATE_FORMAT),\n",
    "                \"Rise Time (Local)\": local_rise.strftime(TIME_FORMAT),\n",
    "                \"Set Time (Local)\": local_set.strftime(TIME_FORMAT),\n",
    "                \"Peak Time (Local)\": local_peak.strftime(TIME_FORMAT),\n",
    "                \"Min Sun Alt(°)\": round(min_sun_alt, 1),\n",
    "                \"ISS Peak Alt(°)\": round(iss_peak_alt, 1),\n",
    "                \"Duration (min)\": round((dt_set - dt_rise).total_seconds() / 60, 1)\n",
    "            })\n",
    "\n",
    "    return passes_data, epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d126850c",
   "metadata": {},
   "source": [
    "## 6) Analysis & Visualization\n",
    "\n",
    "Functions to compute accuracy metrics from observed data and create simple matplotlib visualizations (observation rate, error histograms, and visibility vs altitude). These accept pandas DataFrames and produce figures or metric summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a811e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== ANALYSIS & VISUALIZATION =====================\n",
    "def calculate_accuracy_metrics(df):\n",
    "    \"\"\"Calculate prediction accuracy metrics\"\"\"\n",
    "    # Filter to only predictions that have observations\n",
    "    observed_predictions = df[df['observed'].notna()]\n",
    "\n",
    "    if len(observed_predictions) == 0:\n",
    "        return None\n",
    "\n",
    "    # Calculate overall accuracy (predicted pass was actually observed)\n",
    "    accuracy = observed_predictions['observed'].mean() * 100\n",
    "\n",
    "    # Calculate time differences where we have actual times\n",
    "    time_diff_metrics = {}\n",
    "\n",
    "    # Process rise time differences\n",
    "    rise_times = observed_predictions[observed_predictions['actual_rise_time'] != '']\n",
    "    if len(rise_times) > 0:\n",
    "        rise_diff = []\n",
    "        for _, row in rise_times.iterrows():\n",
    "            pred = datetime.strptime(f\"{row['prediction_date']} {row['rise_time_local']}\",\n",
    "                                     f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            actual = datetime.strptime(f\"{row['prediction_date']} {row['actual_rise_time']}\",\n",
    "                                       f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            rise_diff.append(abs((actual - pred).total_seconds() / 60))  # minutes\n",
    "        time_diff_metrics['rise'] = {\n",
    "            'mean': np.mean(rise_diff),\n",
    "            'median': np.median(rise_diff),\n",
    "            'max': np.max(rise_diff)\n",
    "        }\n",
    "\n",
    "    # Process peak time differences\n",
    "    peak_times = observed_predictions[observed_predictions['actual_peak_time'] != '']\n",
    "    if len(peak_times) > 0:\n",
    "        peak_diff = []\n",
    "        for _, row in peak_times.iterrows():\n",
    "            pred = datetime.strptime(f\"{row['prediction_date']} {row['peak_time_local']}\",\n",
    "                                     f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            actual = datetime.strptime(f\"{row['prediction_date']} {row['actual_peak_time']}\",\n",
    "                                       f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            peak_diff.append(abs((actual - pred).total_seconds() / 60))  # minutes\n",
    "        time_diff_metrics['peak'] = {\n",
    "            'mean': np.mean(peak_diff),\n",
    "            'median': np.median(peak_diff),\n",
    "            'max': np.max(peak_diff)\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'total_predictions': len(df),\n",
    "        'total_observed': len(observed_predictions),\n",
    "        'accuracy': accuracy,\n",
    "        'time_diffs': time_diff_metrics\n",
    "    }\n",
    "\n",
    "\n",
    "def create_visualizations(df):\n",
    "    \"\"\"Create visualization of prediction accuracy\"\"\"\n",
    "    # Filter to only predictions that have observations\n",
    "    observed_predictions = df[df['observed'].notna()]\n",
    "\n",
    "    if len(observed_predictions) == 0:\n",
    "        st.info(\"No observation data available for visualization. Enter some observation data first.\")\n",
    "        return\n",
    "\n",
    "    # 1. Observation Rate Bar Chart\n",
    "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    observation_counts = observed_predictions['observed'].value_counts()\n",
    "    ax1.bar(['Observed', 'Not Observed'],\n",
    "            [observation_counts.get(1, 0), observation_counts.get(0, 0)],\n",
    "            color=['green', 'red'])\n",
    "    ax1.set_title('Observation Rate of Predicted Passes')\n",
    "    ax1.set_ylabel('Number of Passes')\n",
    "    ax1.set_ylim(0, max(observation_counts) + 1)\n",
    "    st.pyplot(fig1)\n",
    "\n",
    "    # 2. Time Difference Histogram\n",
    "    time_diffs = []\n",
    "    labels = []\n",
    "\n",
    "    # Check for rise time differences\n",
    "    rise_times = observed_predictions[observed_predictions['actual_rise_time'] != '']\n",
    "    if len(rise_times) > 0:\n",
    "        for _, row in rise_times.iterrows():\n",
    "            pred = datetime.strptime(f\"{row['prediction_date']} {row['rise_time_local']}\",\n",
    "                                     f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            actual = datetime.strptime(f\"{row['prediction_date']} {row['actual_rise_time']}\",\n",
    "                                       f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            time_diffs.append(abs((actual - pred).total_seconds() / 60))  # minutes\n",
    "            labels.append('Rise')\n",
    "\n",
    "    # Check for peak time differences\n",
    "    peak_times = observed_predictions[observed_predictions['actual_peak_time'] != '']\n",
    "    if len(peak_times) > 0:\n",
    "        for _, row in peak_times.iterrows():\n",
    "            pred = datetime.strptime(f\"{row['prediction_date']} {row['peak_time_local']}\",\n",
    "                                     f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            actual = datetime.strptime(f\"{row['prediction_date']} {row['actual_peak_time']}\",\n",
    "                                       f\"{DATE_FORMAT} {TIME_FORMAT}\")\n",
    "            time_diffs.append(abs((actual - pred).total_seconds() / 60))  # minutes\n",
    "            labels.append('Peak')\n",
    "\n",
    "    if time_diffs:\n",
    "        fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "        ax2.hist(time_diffs, bins=10, alpha=0.7)\n",
    "        ax2.set_title('Distribution of Time Prediction Errors (minutes)')\n",
    "        ax2.set_xlabel('Time Difference (minutes)')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        st.pyplot(fig2)\n",
    "\n",
    "    # 3. Visibility vs Predicted Altitude\n",
    "    rated_obs = observed_predictions[observed_predictions['visibility_rating'].notna()]\n",
    "    if len(rated_obs) > 0:\n",
    "        fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "        ax3.scatter(rated_obs['iss_peak_alt'], rated_obs['visibility_rating'])\n",
    "        ax3.set_title('Visibility Rating vs Predicted ISS Peak Altitude')\n",
    "        ax3.set_xlabel('Predicted ISS Peak Altitude (°)')\n",
    "        ax3.set_ylabel('Visibility Rating (1-5)')\n",
    "        ax3.set_ylim(0, 6)\n",
    "        st.pyplot(fig3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa42ff96",
   "metadata": {},
   "source": [
    "## 7) Streamlit application (main)\n",
    "\n",
    "This final cell contains the Streamlit app `main()` function which wires together the pieces: database initialization, UI tabs for generating predictions, logging observations, and analysis/visualization. Running this cell with `streamlit run` will start the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== STREAMLIT APP =====================\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"ISS Visibility Predictor\", layout=\"wide\")\n",
    "    st.title(\"ISS Visibility Predictor & Tracker\")\n",
    "\n",
    "    # Initialize database\n",
    "    init_db()\n",
    "\n",
    "    # Create tabs\n",
    "    tab1, tab2, tab3 = st.tabs([\"Generate Predictions\", \"Log Observations\", \"Analysis & Visualization\"])\n",
    "\n",
    "    with tab1:\n",
    "        st.header(\"Generate ISS Visibility Predictions\")\n",
    "\n",
    "        # User input\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            lat = st.number_input(\"Latitude (°)\", min_value=-90.0, max_value=90.0, value=0.0, step=0.01)\n",
    "            lon = st.number_input(\"Longitude (°)\", min_value=-180.0, max_value=180.0, value=0.0, step=0.01)\n",
    "\n",
    "        with col2:\n",
    "            today = datetime.now().strftime(DATE_FORMAT)\n",
    "            start_date = st.text_input(\"Start Date (YYYY-MM-DD)\", value=today)\n",
    "\n",
    "        if st.button(\"Generate Predictions\"):\n",
    "            # Validate inputs\n",
    "            try:\n",
    "                datetime.strptime(start_date, DATE_FORMAT)\n",
    "            except ValueError:\n",
    "                st.error(\"Invalid date format. Please use YYYY-MM-DD.\")\n",
    "                return\n",
    "\n",
    "            if not (-90 <= lat <= 90 and -180 <= lon <= 180):\n",
    "                st.error(\"Latitude must be between -90 and 90, longitude between -180 and 180.\")\n",
    "                return\n",
    "\n",
    "            # Generate predictions\n",
    "            with st.spinner(\"Calculating ISS visibility predictions...\"):\n",
    "                predictions, epoch = generate_iss_predictions(lat, lon, start_date)\n",
    "\n",
    "                if predictions:\n",
    "                    st.success(f\"Successfully generated {len(predictions)} predictions! TLE Epoch: {epoch}\")\n",
    "\n",
    "                    # Save to database\n",
    "                    prediction_ids = save_predictions_to_db(predictions, lat, lon)\n",
    "\n",
    "                    # Display predictions\n",
    "                    df = pd.DataFrame(predictions)\n",
    "                    st.dataframe(df)\n",
    "\n",
    "                    # Add download option\n",
    "                    csv = df.to_csv(index=False)\n",
    "                    st.download_button(\n",
    "                        label=\"Download predictions as CSV\",\n",
    "                        data=csv,\n",
    "                        file_name=\"iss_predictions.csv\",\n",
    "                        mime=\"text/csv\",\n",
    "                    )\n",
    "                else:\n",
    "                    st.warning(\"No visible nighttime ISS passes found for the given parameters.\")\n",
    "\n",
    "    with tab2:\n",
    "        st.header(\"Log Observation Data\")\n",
    "\n",
    "        # Get all predictions without observations\n",
    "        conn = sqlite3.connect(DB_NAME)\n",
    "        query = '''SELECT p.id, p.prediction_date, p.rise_time_local, p.peak_time_local, \n",
    "                          p.set_time_local, p.iss_peak_alt, p.latitude, p.longitude\n",
    "                   FROM predictions p\n",
    "                   LEFT JOIN observations o ON p.id = o.prediction_id\n",
    "                   WHERE o.id IS NULL'''\n",
    "        predictions_df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "\n",
    "        if len(predictions_df) == 0:\n",
    "            st.info(\"No predictions available to log observations for. Generate some predictions first.\")\n",
    "        else:\n",
    "            # Let user select a prediction to log\n",
    "            prediction_id = st.selectbox(\n",
    "                \"Select a prediction to log an observation for:\",\n",
    "                predictions_df['id'],\n",
    "                format_func=lambda\n",
    "                    x: f\"ID {x}: {predictions_df.loc[predictions_df['id'] == x, 'prediction_date'].iloc[0]} \"\n",
    "                       f\"({predictions_df.loc[predictions_df['id'] == x, 'rise_time_local'].iloc[0]} - \"\n",
    "                       f\"{predictions_df.loc[predictions_df['id'] == x, 'set_time_local'].iloc[0]})\"\n",
    "            )\n",
    "\n",
    "            # Get selected prediction details\n",
    "            selected_pred = predictions_df[predictions_df['id'] == prediction_id].iloc[0]\n",
    "\n",
    "            # Display prediction details\n",
    "            st.subheader(\"Prediction Details\")\n",
    "            st.write(f\"Date: {selected_pred['prediction_date']}\")\n",
    "            st.write(f\"Location: Lat {selected_pred['latitude']}, Lon {selected_pred['longitude']}\")\n",
    "            st.write(f\"Predicted Rise Time: {selected_pred['rise_time_local']}\")\n",
    "            st.write(f\"Predicted Peak Time: {selected_pred['peak_time_local']}\")\n",
    "            st.write(f\"Predicted Set Time: {selected_pred['set_time_local']}\")\n",
    "            st.write(f\"Predicted Peak Altitude: {selected_pred['iss_peak_alt']}°\")\n",
    "\n",
    "            # Observation form\n",
    "            st.subheader(\"Observation Data\")\n",
    "            observed = st.radio(\"Did you observe the ISS during this pass?\", [\"Yes\", \"No\"])\n",
    "            observed_bool = observed == \"Yes\"\n",
    "\n",
    "            actual_times = {}\n",
    "            if observed_bool:\n",
    "                col1, col2, col3 = st.columns(3)\n",
    "                with col1:\n",
    "                    actual_rise = st.text_input(\"Actual Rise Time (HH:MM:SS)\", value=selected_pred['rise_time_local'])\n",
    "                    actual_times['rise'] = actual_rise\n",
    "                with col2:\n",
    "                    actual_peak = st.text_input(\"Actual Peak Time (HH:MM:SS)\", value=selected_pred['peak_time_local'])\n",
    "                    actual_times['peak'] = actual_peak\n",
    "                with col3:\n",
    "                    actual_set = st.text_input(\"Actual Set Time (HH:MM:SS)\", value=selected_pred['set_time_local'])\n",
    "                    actual_times['set'] = actual_set\n",
    "\n",
    "                visibility = st.slider(\"Visibility Rating (1=Poor, 5=Excellent)\", 1, 5, 3)\n",
    "            else:\n",
    "                visibility = None\n",
    "\n",
    "            notes = st.text_area(\"Additional Notes (e.g., weather conditions, obstacles)\", \"\")\n",
    "\n",
    "            if st.button(\"Save Observation\"):\n",
    "                # Validate time formats if provided\n",
    "                time_format_valid = True\n",
    "                if observed_bool:\n",
    "                    for time_type, time_str in actual_times.items():\n",
    "                        try:\n",
    "                            datetime.strptime(time_str, TIME_FORMAT)\n",
    "                        except ValueError:\n",
    "                            st.error(f\"Invalid {time_type} time format. Please use HH:MM:SS.\")\n",
    "                            time_format_valid = False\n",
    "                            break\n",
    "\n",
    "                if time_format_valid:\n",
    "                    save_observation_to_db(prediction_id, observed_bool, actual_times, visibility, notes)\n",
    "                    st.success(\"Observation saved successfully!\")\n",
    "                    st.rerun()\n",
    "\n",
    "    with tab3:\n",
    "        st.header(\"Prediction Accuracy Analysis\")\n",
    "\n",
    "        # Get all data\n",
    "        df = get_all_predictions_with_observations()\n",
    "\n",
    "        if len(df) == 0:\n",
    "            st.info(\"No prediction data available. Generate some predictions first.\")\n",
    "        else:\n",
    "            # Calculate metrics\n",
    "            metrics = calculate_accuracy_metrics(df)\n",
    "\n",
    "            if metrics:\n",
    "                # Display metrics\n",
    "                col1, col2, col3 = st.columns(3)\n",
    "                with col1:\n",
    "                    st.metric(\"Total Predictions\", metrics['total_predictions'])\n",
    "                with col2:\n",
    "                    st.metric(\"Predictions with Observations\", metrics['total_observed'])\n",
    "                with col3:\n",
    "                    st.metric(\"Observation Accuracy\", f\"{metrics['accuracy']:.1f}%\")\n",
    "\n",
    "                # Display time difference metrics\n",
    "                if metrics['time_diffs']:\n",
    "                    st.subheader(\"Time Prediction Accuracy (minutes)\")\n",
    "                    time_metrics_df = pd.DataFrame()\n",
    "\n",
    "                    for time_type, stats in metrics['time_diffs'].items():\n",
    "                        time_metrics_df = pd.concat([time_metrics_df, pd.DataFrame({\n",
    "                            'Time Type': [time_type.capitalize()],\n",
    "                            'Mean Difference': [f\"{stats['mean']:.1f}\"],\n",
    "                            'Median Difference': [f\"{stats['median']:.1f}\"],\n",
    "                            'Max Difference': [f\"{stats['max']:.1f}\"]\n",
    "                        })], ignore_index=True)\n",
    "\n",
    "                    st.dataframe(time_metrics_df)\n",
    "\n",
    "            # Display visualizations\n",
    "            st.subheader(\"Accuracy Visualizations\")\n",
    "            create_visualizations(df)\n",
    "\n",
    "            # Display raw data\n",
    "            with st.expander(\"View Raw Data\"):\n",
    "                st.dataframe(df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
